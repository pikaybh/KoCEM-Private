# KoCEM: A Multimodal Knowledge and Reasoning Benchmark for Korean Construction Engineering & Management

## Leaderboard

<p>Per-locale rankings. First, per split tables; then an overall weighted table. Columns show subject accuracies. Higher is better.</p>

## Locale: en

### Locale: en — Split: dev

<table>
<thead>
<tr><th>Rank</th><th>Model</th><th>Total</th><th>Architectural_Planning</th><th>Building_System</th><th>Comprehensive_Understanding</th><th>Construction_Management</th><th>Domain_Reasoning</th><th>Drawing_Interpretation</th><th>Interior</th><th>Materials</th><th>Safety_Management</th><th>Standard_Nomenclature</th><th>Structural_Engineering</th></tr>
</thead>
<tbody>
<tr><td>1</td><td>gpt-5</td><td>87.23%</td><td>33.33%</td><td>100.00%</td><td>66.67%</td><td>100.00%</td><td>66.67%</td><td>66.67%</td><td>83.33%</td><td>100.00%</td><td>100.00%</td><td>100.00%</td><td>100.00%</td></tr>
<tr><td>2</td><td>claude-opus-4-1</td><td>84.21%</td><td>66.67%</td><td>80.00%</td><td>100.00%</td><td>100.00%</td><td>66.67%</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr>
<tr><td>3</td><td>gpt-oss-120b</td><td>82.98%</td><td>66.67%</td><td>60.00%</td><td>33.33%</td><td>100.00%</td><td>66.67%</td><td>66.67%</td><td>83.33%</td><td>100.00%</td><td>100.00%</td><td>100.00%</td><td>100.00%</td></tr>
<tr><td>4</td><td>gpt-4.1</td><td>78.72%</td><td>66.67%</td><td>80.00%</td><td>66.67%</td><td>100.00%</td><td>33.33%</td><td>100.00%</td><td>83.33%</td><td>87.50%</td><td>75.00%</td><td>100.00%</td><td>0.00%</td></tr>
<tr><td>5</td><td>gpt-oss-20b</td><td>72.34%</td><td>66.67%</td><td>80.00%</td><td>33.33%</td><td>100.00%</td><td>33.33%</td><td>66.67%</td><td>50.00%</td><td>75.00%</td><td>75.00%</td><td>100.00%</td><td>100.00%</td></tr>
<tr><td>6</td><td>llama4-scout</td><td>46.81%</td><td>33.33%</td><td>60.00%</td><td>33.33%</td><td>20.00%</td><td>66.67%</td><td>66.67%</td><td>50.00%</td><td>50.00%</td><td>50.00%</td><td>40.00%</td><td>50.00%</td></tr>
</tbody>
</table>

### Locale: en — Split: test

<table>
<thead>
<tr><th>Rank</th><th>Model</th><th>Total</th><th>Architectural_Planning</th><th>Building_System</th><th>Comprehensive_Understanding</th><th>Construction_Management</th><th>Domain_Reasoning</th><th>Drawing_Interpretation</th><th>Interior</th><th>Materials</th><th>Safety_Management</th><th>Standard_Nomenclature</th><th>Structural_Engineering</th></tr>
</thead>
<tbody>
<tr><td>1</td><td>gpt-5</td><td>83.28%</td><td>85.47%</td><td>89.10%</td><td>51.55%</td><td>81.76%</td><td>75.69%</td><td>68.85%</td><td>68.63%</td><td>91.40%</td><td>82.71%</td><td>100.00%</td><td>86.26%</td></tr>
<tr><td>2</td><td>claude-opus-4-1</td><td>75.69%</td><td>79.83%</td><td>83.65%</td><td>52.80%</td><td>79.92%</td><td>63.14%</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr>
<tr><td>3</td><td>gpt-4.1</td><td>72.74%</td><td>75.92%</td><td>78.75%</td><td>45.96%</td><td>77.05%</td><td>47.84%</td><td>48.36%</td><td>64.15%</td><td>84.77%</td><td>73.14%</td><td>99.56%</td><td>54.68%</td></tr>
<tr><td>4</td><td>gpt-oss-120b</td><td>69.23%</td><td>71.80%</td><td>72.48%</td><td>24.22%</td><td>70.29%</td><td>53.73%</td><td>36.89%</td><td>59.66%</td><td>85.01%</td><td>69.68%</td><td>100.00%</td><td>55.26%</td></tr>
<tr><td>5</td><td>gpt-oss-20b</td><td>66.24%</td><td>68.11%</td><td>69.21%</td><td>30.43%</td><td>67.42%</td><td>42.75%</td><td>45.90%</td><td>54.34%</td><td>78.13%</td><td>68.35%</td><td>99.56%</td><td>52.63%</td></tr>
<tr><td>6</td><td>llama4-scout</td><td>55.44%</td><td>58.79%</td><td>61.85%</td><td>18.01%</td><td>59.22%</td><td>52.94%</td><td>31.97%</td><td>52.10%</td><td>66.34%</td><td>57.18%</td><td>57.56%</td><td>52.34%</td></tr>
</tbody>
</table>

### Locale: en — Split: val

<table>
<thead>
<tr><th>Rank</th><th>Model</th><th>Total</th><th>Architectural_Planning</th><th>Building_System</th><th>Comprehensive_Understanding</th><th>Construction_Management</th><th>Domain_Reasoning</th><th>Drawing_Interpretation</th><th>Interior</th><th>Materials</th><th>Safety_Management</th><th>Standard_Nomenclature</th><th>Structural_Engineering</th></tr>
</thead>
<tbody>
<tr><td>1</td><td>gpt-5</td><td>76.23%</td><td>85.37%</td><td>93.88%</td><td>52.87%</td><td>82.35%</td><td>70.00%</td><td>55.56%</td><td>80.43%</td><td>90.70%</td><td>85.37%</td><td>100.00%</td><td>82.35%</td></tr>
<tr><td>2</td><td>claude-opus-4-1</td><td>69.75%</td><td>80.49%</td><td>83.67%</td><td>58.60%</td><td>88.24%</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr>
<tr><td>3</td><td>gpt-4.1</td><td>69.55%</td><td>80.49%</td><td>81.63%</td><td>45.22%</td><td>70.59%</td><td>40.00%</td><td>55.56%</td><td>82.61%</td><td>90.70%</td><td>85.37%</td><td>100.00%</td><td>58.82%</td></tr>
<tr><td>4</td><td>gpt-oss-20b</td><td>60.71%</td><td>65.85%</td><td>67.35%</td><td>31.85%</td><td>79.41%</td><td>30.00%</td><td>33.33%</td><td>69.57%</td><td>86.05%</td><td>75.61%</td><td>100.00%</td><td>61.76%</td></tr>
<tr><td>5</td><td>gpt-oss-120b</td><td>60.31%</td><td>75.61%</td><td>73.47%</td><td>29.94%</td><td>73.53%</td><td>50.00%</td><td>33.33%</td><td>65.22%</td><td>83.72%</td><td>80.49%</td><td>100.00%</td><td>47.06%</td></tr>
<tr><td>6</td><td>llama4-scout</td><td>46.95%</td><td>63.41%</td><td>57.14%</td><td>16.56%</td><td>73.53%</td><td>20.00%</td><td>33.33%</td><td>65.22%</td><td>55.81%</td><td>73.17%</td><td>57.78%</td><td>55.88%</td></tr>
</tbody>
</table>

### Locale: en — All splits (weighted)

<table>
<thead>
<tr><th>Rank</th><th>Model</th><th>Total</th><th>Architectural_Planning</th><th>Building_System</th><th>Comprehensive_Understanding</th><th>Construction_Management</th><th>Domain_Reasoning</th><th>Drawing_Interpretation</th><th>Interior</th><th>Materials</th><th>Safety_Management</th><th>Standard_Nomenclature</th><th>Structural_Engineering</th></tr>
</thead>
<tbody>
<tr><td>1</td><td>gpt-5</td><td>82.50%</td><td>85.15%</td><td>89.79%</td><td>52.34%</td><td>81.97%</td><td>75.37%</td><td>67.91%</td><td>70.17%</td><td>91.48%</td><td>83.14%</td><td>100.00%</td><td>85.98%</td></tr>
<tr><td>2</td><td>claude-opus-4-1</td><td>74.95%</td><td>79.80%</td><td>83.61%</td><td>56.07%</td><td>80.65%</td><td>63.18%</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr>
<tr><td>3</td><td>gpt-4.1</td><td>72.43%</td><td>76.24%</td><td>79.10%</td><td>45.79%</td><td>76.85%</td><td>47.39%</td><td>50.00%</td><td>66.50%</td><td>85.37%</td><td>74.35%</td><td>99.60%</td><td>54.76%</td></tr>
<tr><td>4</td><td>gpt-oss-120b</td><td>68.33%</td><td>72.08%</td><td>72.45%</td><td>27.10%</td><td>70.78%</td><td>53.73%</td><td>37.31%</td><td>60.64%</td><td>85.15%</td><td>71.02%</td><td>100.00%</td><td>54.76%</td></tr>
<tr><td>5</td><td>gpt-oss-20b</td><td>65.66%</td><td>67.92%</td><td>69.12%</td><td>31.15%</td><td>68.50%</td><td>42.16%</td><td>45.52%</td><td>55.99%</td><td>78.82%</td><td>69.12%</td><td>99.60%</td><td>53.70%</td></tr>
<tr><td>6</td><td>llama4-scout</td><td>54.35%</td><td>59.01%</td><td>61.28%</td><td>17.45%</td><td>59.77%</td><td>51.87%</td><td>32.84%</td><td>53.55%</td><td>65.07%</td><td>58.67%</td><td>57.40%</td><td>52.65%</td></tr>
</tbody>
</table>



## Evaluation Guidelines
This repo provides a simple CLI to run evaluation over KoCEM subjects, produce outputs, and update the README leaderboard.

### Output layout
Results are saved under `output/<prompt>/<locale>/<model>/<split>/<subject>/` as:

```
output/
	<prompt>/            # e.g., mcqa (preferred) or test (fallback)
		<locale>/          # e.g., en, ko
			<model>/         # e.g., gpt-4.1
				<split>/       # dev, test, val, extra
					<subject>/   # e.g., Architectural_Planning
						output.json        # per-sample entries with predictions and judges
						evaluation.json    # per-sample judge details
						result.json        # aggregated metrics (acc, std_dev, num_example, ...)
```

### Run inference
Use the `run_each` command to generate predictions and metrics.

```pwsh
uv run python -m app run_each --model gpt-4.1 --locale en --subjects Architectural_Planning --splits dev --prompt test

# Multiple subjects
uv run python -m app run_each --model gpt-4.1 --locale en --subjects '["Architectural_Planning","Materials"]' --splits '["dev","val"]' --prompt test
```

### Evaluate difficulties (optional)
If a subject provides difficulty labels, compute difficulty-wise metrics from saved outputs:

```pwsh
uv run python -m app eval_difficulties --model gpt-4.1 --prompt test --locale en
```

### Update README leaderboard
Generate per-locale leaderboards and inject them into this README:

```pwsh
uv run python -m app.update_readme
```

The updater prefers `output/mcqa`; if absent, it falls back to `output/test`.

### Prompts
Prompts live under `prompts/<locale>/...`. Pick a prompt by name with `--prompt` (e.g., `test`, `mcqa`).

### Configuration
Set the following environment variables (via `.env` or shell) as needed:

- `DS_PATH`: Hugging Face dataset path (e.g., `pikaybh/KoCEM`)
- `DS_CACHE_PATH`: HF cache directory
- `OUTPUT_PATH`: Root directory for outputs (defaults to `./output`)
- Provider credentials (e.g., OpenAI) according to your model choice
